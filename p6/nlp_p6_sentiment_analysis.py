# -*- coding: utf-8 -*-
"""NLP_P6_Sentiment_Analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Ea5ITeZ8pmW_epj5PngqENCzhFbUW6PS
"""

from sklearn.feature_extraction.text import CountVectorizer
import numpy as np
import pandas as pd
import os, pickle
from sklearn.linear_model import LogisticRegression
from  sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn.model_selection import cross_validate
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.model_selection import train_test_split, cross_validate
from sklearn.svm import LinearSVC
import spacy
import pandas as pd

# Cargamos el archivo excel
excel_path = 'Rest_Mex_2022.xlsx'
df = pd.read_excel(excel_path)
df.head()

# Verify if the model is installed
#!pip show es_core_news_sm

# If not installed, install the model
#!pip install es_core_news_sm

# Load the model
nlp = spacy.load('es_core_news_sm')

import pandas as pd
import spacy
import os, pickle

nlp = spacy.load('es_core_news_sm')

# Función para lematizar el texto
def lematizar_texto(texto):
    # Convertir la entrada a cadena si no lo es
    texto = str(texto) if not isinstance(texto, str) else texto
    doc = nlp(texto)
    return ' '.join([token.lemma_ for token in doc])

# Cargar tus datos
df = pd.read_excel('Rest_Mex_2022.xlsx')

# Lematización a la columna 'Opinion'
df['Opinion_Lematizada'] = df['Opinion'].apply(lematizar_texto)

# DataFrame solo con las columnas Opinión y Polaridad
df_reducido = df[['Opinion_Lematizada', 'Polarity']]

# Guardar el nuevo DataFrame en un archivo pickle
df_reducido.to_pickle('lematizado_polaridad.pkl')

df_reducido = pd.read_pickle('lematizado_polaridad.pkl')
df_reducido.head()

df_reducido.to_csv('noticiaPolaridad.csv', index=False)

df = pd.read_csv('noticiaPolaridad.csv')
df.head()

from sklearn.model_selection import train_test_split

df = pd.read_csv('noticiaPolaridad.csv')

# 'Opinion_Lematizada' es el texto y 'Polarity' es la etiqueta
X = df['Opinion_Lematizada']
y = df['Polarity']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

print(X_train.head())
print(y_train.head())
print(X_test.head())
print(y_test.head())

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split

vectorizer = TfidfVectorizer()
X_train_tfidf = vectorizer.fit_transform(X_train)
X_test_tfidf = vectorizer.transform(X_test)

feature_names = vectorizer.get_feature_names_out()
print(feature_names[2950:2960])

print(X_train_tfidf.shape)
print(X_train_tfidf.toarray()[2950:2960, 2950:2960])

primer_documento = X_train.iloc[0]
print("Texto del primer documento:", primer_documento)

doc_id = 0  # Índice del primer documento en X_train
feature_names = vectorizer.get_feature_names_out()
doc_tfidf = X_train_tfidf[doc_id].toarray().flatten()
tfidf_pairs = zip(feature_names, doc_tfidf)
print(sorted(tfidf_pairs, key=lambda x: x[1], reverse=True)[:10])  # Imprime las 10 características con mayor TF-IDF

from sklearn.svm import LinearSVC
from sklearn.metrics import accuracy_score

# Modelo LinealSVC + TF-IDF
clf_polarity = LinearSVC(  max_iter=30000, C=1.0, verbose=1)
clf_polarity.fit(X_train_tfidf, y_train)

# conjunto de prueba
y_pred = clf_polarity.predict(X_test_tfidf)

# predicciones
print(y_pred)

# precisión
print("Accuracy:", accuracy_score(y_test, y_pred))

from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report

#  matriz de confusión
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

#  informe de clasificación
print("Classification Report:\n", classification_report(y_test, y_pred))

from sklearn.model_selection import cross_validate
from sklearn.svm import LinearSVC
import numpy as np

# Realizamos validación cruzada
print('Realizando validación cruzada...')
cv_results = cross_validate(clf_polarity, X_train_tfidf, y_train, cv=5, scoring='f1_macro', verbose=3, n_jobs=-1)

# Imprimimos los resultados de la validación cruzada
print(cv_results)

# Promedio de f1_macro en validación cruzada
print('Media de f1_macro en validación cruzada: ', np.mean(cv_results['test_score']))

#!pip install sklearn

from sklearn.linear_model import LogisticRegression
import sys

# Modelo REGRESIÓN LOGÍSITCA + TF-IDF
clf_polarity = LogisticRegression(max_iter=30000, C=1.0, verbose=1)
clf_polarity.fit(X_train_tfidf, y_train)

y_pred = clf_polarity.predict(X_test_tfidf)

print(y_pred)

print("Accuracy:", accuracy_score(y_test, y_pred))

print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

print("Classification Report:\n", classification_report(y_test, y_pred))

print('Realizando validación cruzada...')
cv_results = cross_validate(clf_polarity, X_train_tfidf, y_train, cv=5, scoring='f1_macro', verbose=3, n_jobs=-1)

print(cv_results)
print('Media de f1_macro en validación cruzada: ', np.mean(cv_results['test_score']))

from sklearn.neural_network import MLPClassifier

# Modelo NEURAL NETWORKS + TF-IDF
clf_polarity = MLPClassifier(hidden_layer_sizes=(100,), max_iter = 1000, random_state=1)
clf_polarity.fit(X_train_tfidf, y_train)

y_pred = clf_polarity.predict(X_test_tfidf)

print("Accuracy:", accuracy_score(y_test, y_pred))

print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

print("Classification Report:\n", classification_report(y_test, y_pred))

print('Realizando validación cruzada...')
cv_results = cross_validate(clf_polarity, X_train_tfidf, y_train, cv=5, scoring='f1_macro', verbose=3, n_jobs=-1)

print(cv_results)
print('Media de f1_macro en validación cruzada: ', np.mean(cv_results['test_score']))