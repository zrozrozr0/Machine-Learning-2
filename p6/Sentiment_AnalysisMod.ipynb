{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "mdieRAqgs6lq"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os, pickle\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from  sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split, cross_validate\n",
        "from sklearn.svm import LinearSVC\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OZCOXPVbs6lv",
        "outputId": "3dddb3b7-4b65-4737-b90c-c428f22d1877"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Opinion</th>\n",
              "      <th>Polarity</th>\n",
              "      <th>Attraction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Pésimo lugar</td>\n",
              "      <td>Piensen dos veces antes de ir a este hotel, te...</td>\n",
              "      <td>1</td>\n",
              "      <td>Hotel</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>No vayas a lugar de Eddie</td>\n",
              "      <td>Cuatro de nosotros fuimos recientemente a Eddi...</td>\n",
              "      <td>1</td>\n",
              "      <td>Restaurant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Mala relación calidad-precio</td>\n",
              "      <td>seguiré corta y simple: limpieza\\n- bad. Tengo...</td>\n",
              "      <td>1</td>\n",
              "      <td>Hotel</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Minusválido? ¡No te alojes aquí!</td>\n",
              "      <td>Al reservar un hotel con multipropiedad Mayan ...</td>\n",
              "      <td>1</td>\n",
              "      <td>Hotel</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Es una porqueria no pierdan su tiempo</td>\n",
              "      <td>No pierdan su tiempo ni dinero, venimos porque...</td>\n",
              "      <td>1</td>\n",
              "      <td>Hotel</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                   Title  \\\n",
              "0                           Pésimo lugar   \n",
              "1              No vayas a lugar de Eddie   \n",
              "2           Mala relación calidad-precio   \n",
              "3       Minusválido? ¡No te alojes aquí!   \n",
              "4  Es una porqueria no pierdan su tiempo   \n",
              "\n",
              "                                             Opinion  Polarity  Attraction  \n",
              "0  Piensen dos veces antes de ir a este hotel, te...         1       Hotel  \n",
              "1  Cuatro de nosotros fuimos recientemente a Eddi...         1  Restaurant  \n",
              "2  seguiré corta y simple: limpieza\\n- bad. Tengo...         1       Hotel  \n",
              "3  Al reservar un hotel con multipropiedad Mayan ...         1       Hotel  \n",
              "4  No pierdan su tiempo ni dinero, venimos porque...         1       Hotel  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Cargamos el archivo excel\n",
        "excel_path = 'Rest_Mex_2022.xlsx'\n",
        "df = pd.read_excel(excel_path)\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3GBmzWlYs6lw"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import spacy\n",
        "import os, pickle\n",
        "\n",
        "nlp = spacy.load('es_core_news_sm')\n",
        "\n",
        "# Función para lematizar el texto\n",
        "def lematizar_texto(texto):\n",
        "    # Convertir la entrada a cadena si no lo es\n",
        "    texto = str(texto) if not isinstance(texto, str) else texto\n",
        "    doc = nlp(texto)\n",
        "    return ' '.join([token.lemma_ for token in doc])\n",
        "\n",
        "# Cargar tus datos\n",
        "df = pd.read_excel('Rest_Mex_2022.xlsx')\n",
        "\n",
        "# Lematización a la columna 'Opinion'\n",
        "df['Opinion_Lematizada'] = df['Opinion'].apply(lematizar_texto)\n",
        "\n",
        "# DataFrame solo con las columnas Opinión y Polaridad\n",
        "df_reducido = df[['Opinion_Lematizada', 'Polarity']]\n",
        "\n",
        "# Guardar el nuevo DataFrame en un archivo pickle\n",
        "df_reducido.to_pickle('lematizado_polaridad.pkl')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJ7X9W8Ss6lx",
        "outputId": "7396384f-f4f0-4776-debb-0043be3b53c4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Opinion_Lematizada</th>\n",
              "      <th>Polarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>piensir dos vez antes de ir a este hotel , tú ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>cuatro de yo ir recientemente a Eddie's Place ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>seguir corto y simple : limpieza \\n - bad . te...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>al reservar uno hotel con multipropiedad Mayan...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>no perder su tiempo ni dinero , venir porque t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  Opinion_Lematizada  Polarity\n",
              "0  piensir dos vez antes de ir a este hotel , tú ...         1\n",
              "1  cuatro de yo ir recientemente a Eddie's Place ...         1\n",
              "2  seguir corto y simple : limpieza \\n - bad . te...         1\n",
              "3  al reservar uno hotel con multipropiedad Mayan...         1\n",
              "4  no perder su tiempo ni dinero , venir porque t...         1"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_reducido = pd.read_pickle('lematizado_polaridad.pkl')\n",
        "df_reducido.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w4wi7icNs6lx"
      },
      "outputs": [],
      "source": [
        "df_reducido.to_csv('noticiaPolaridad.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bzg8pVX2s6ly",
        "outputId": "073a4579-14e4-4470-b9de-141d0c3c3d4d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Opinion_Lematizada</th>\n",
              "      <th>Polarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>piensir dos vez antes de ir a este hotel , tú ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>cuatro de yo ir recientemente a Eddie's Place ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>seguir corto y simple : limpieza \\n - bad . te...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>al reservar uno hotel con multipropiedad Mayan...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>no perder su tiempo ni dinero , venir porque t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  Opinion_Lematizada  Polarity\n",
              "0  piensir dos vez antes de ir a este hotel , tú ...         1\n",
              "1  cuatro de yo ir recientemente a Eddie's Place ...         1\n",
              "2  seguir corto y simple : limpieza \\n - bad . te...         1\n",
              "3  al reservar uno hotel con multipropiedad Mayan...         1\n",
              "4  no perder su tiempo ni dinero , venir porque t...         1"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('noticiaPolaridad.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CFgdXCges6ly"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df = pd.read_csv('noticiaPolaridad.csv')\n",
        "\n",
        "# 'Opinion_Lematizada' es el texto y 'Polarity' es la etiqueta\n",
        "X = df['Opinion_Lematizada']\n",
        "y = df['Polarity']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yp8Vmd7os6lz",
        "outputId": "7f19255c-c541-4ecd-cee3-1f958687d873"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "18594    también ahora , abierto solo con comida para l...\n",
            "19690    desde que llegar hotel personal estar mucho at...\n",
            "26183    excelente servicio poner súper tazón todo part...\n",
            "26029    excelente el desayuno mucho abundante gran var...\n",
            "16566    tener masaje minuto por fin pareja Katy , mani...\n",
            "Name: Opinion_Lematizada, dtype: object\n",
            "18594    5\n",
            "19690    5\n",
            "26183    5\n",
            "26029    5\n",
            "16566    5\n",
            "Name: Polarity, dtype: int64\n",
            "9730       cena ser fenomenal , como siempre , servicio...\n",
            "7442     yo encaminar Puerto Vallarta por primero vez c...\n",
            "25844    gran lugar para comer ! Camarón azul , pargo ,...\n",
            "9565     buen comida , abundante , precio regular , sol...\n",
            "718      cenar dos vez períodir dos semana noviembre no...\n",
            "Name: Opinion_Lematizada, dtype: object\n",
            "9730     5\n",
            "7442     4\n",
            "25844    5\n",
            "9565     5\n",
            "718      2\n",
            "Name: Polarity, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(X_train.head())\n",
        "print(y_train.head())\n",
        "print(X_test.head())\n",
        "print(y_test.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WUPVLjx1s6lz"
      },
      "outputs": [],
      "source": [
        "vectorizer = TfidfVectorizer()\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rfXlrbPvs6l0",
        "outputId": "e674eed1-e332-4f21-dfb9-64d1a855a3ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['articular' 'articulo' 'artifact' 'artificial' 'artificioso' 'artificiós'\n",
            " 'artilugio' 'artimaña' 'artir' 'artista']\n"
          ]
        }
      ],
      "source": [
        "feature_names = vectorizer.get_feature_names_out()\n",
        "print(feature_names[2950:2960])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z3YyNKcBs6l0",
        "outputId": "39326a55-2708-4a9b-a3fa-93a0d33b7cf5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(24169, 37058)\n",
            "[[0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.22299311]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]]\n"
          ]
        }
      ],
      "source": [
        "print(X_train_tfidf.shape)\n",
        "print(X_train_tfidf.toarray()[2950:2960, 2950:2960])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qEkEyMm1s6l0",
        "outputId": "5fa71a39-dfe0-4ed7-e68b-5084c6540577"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Texto del primer documento: también ahora , abierto solo con comida para llevar domicilio mejór mejór : mismo sabor , comida caliente servicio amable ... como siempre ! ! ! servicio para llevar , como prometido , respetar % descuento ! con Sabrosa Italia valer pena quedar él casa ! Gracias esperar que todo pasar mucho pronto , tener gana visitar hermoso lugar , verdadero rincón Italia México !\n"
          ]
        }
      ],
      "source": [
        "primer_documento = X_train.iloc[0]\n",
        "print(\"Texto del primer documento:\", primer_documento)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AM0VMLtDs6l1",
        "outputId": "a83ed27e-bf49-4d2f-acb7-a9d5c814a26d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('mejór', 0.5402036802128284), ('italia', 0.3900660402775469), ('domicilio', 0.2160945234700174), ('sabrosa', 0.20556377180439542), ('prometido', 0.19891666271390224), ('rincón', 0.1916552764820894), ('llevar', 0.18761546276072794), ('respetar', 0.17397151680752948), ('gana', 0.14470073427888688), ('descuento', 0.14428847118960025)]\n"
          ]
        }
      ],
      "source": [
        "doc_id = 0  # Índice del primer documento en X_train\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "doc_tfidf = X_train_tfidf[doc_id].toarray().flatten()\n",
        "tfidf_pairs = zip(feature_names, doc_tfidf)\n",
        "print(sorted(tfidf_pairs, key=lambda x: x[1], reverse=True)[:10])  # Imprime las 10 características con mayor TF-IDF\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gPHeURn6s6l1",
        "outputId": "d5bc04de-65b8-45a1-99de-c23b4d0d1748"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LibLinear][5 5 5 ... 5 5 5]\n",
            "Accuracy: 0.7034585470792653\n",
            "Confusion Matrix:\n",
            " [[  47   21   19   10    7]\n",
            " [  22   36   47   23   17]\n",
            " [  20   40  171  127   64]\n",
            " [  11   24  155  474  499]\n",
            " [  12   23  127  524 3523]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.42      0.45      0.44       104\n",
            "           2       0.25      0.25      0.25       145\n",
            "           3       0.33      0.41      0.36       422\n",
            "           4       0.41      0.41      0.41      1163\n",
            "           5       0.86      0.84      0.85      4209\n",
            "\n",
            "    accuracy                           0.70      6043\n",
            "   macro avg       0.45      0.47      0.46      6043\n",
            "weighted avg       0.71      0.70      0.71      6043\n",
            "\n",
            "Realizando validación cruzada...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    8.2s remaining:   12.4s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'fit_time': array([8.2220366 , 8.31764627, 8.44222021, 8.14252424, 5.43173194]), 'score_time': array([0.01700115, 0.01996469, 0.02297664, 0.01851106, 0.01900005]), 'test_score': array([0.43531073, 0.43400835, 0.44405049, 0.43477322, 0.44997009])}\n",
            "Media de f1_macro en validación cruzada:  0.43962257536900984\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   13.7s finished\n"
          ]
        }
      ],
      "source": [
        "# Modelo LinealSVC + TF-IDF\n",
        "clf_polarity = LinearSVC(  max_iter=30000, C=1.0, verbose=1)\n",
        "clf_polarity.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# conjunto de prueba\n",
        "y_pred = clf_polarity.predict(X_test_tfidf)\n",
        "\n",
        "# predicciones\n",
        "print(y_pred)\n",
        "\n",
        "# precisión\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "\n",
        "#  matriz de confusión\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "\n",
        "#  informe de clasificación\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# Realizamos validación cruzada\n",
        "print('Realizando validación cruzada...')\n",
        "cv_results = cross_validate(clf_polarity, X_train_tfidf, y_train, cv=5, scoring='f1_macro', verbose=3, n_jobs=-1)\n",
        "\n",
        "# Imprimimos los resultados de la validación cruzada\n",
        "print(cv_results)\n",
        "\n",
        "# Promedio de f1_macro en validación cruzada\n",
        "print('Media de f1_macro en validación cruzada: ', np.mean(cv_results['test_score']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YzBNBr0js6l1",
        "outputId": "0a428c2b-711b-46c1-b939-46082bee05d4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\marcos\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[5 4 5 ... 5 4 5]\n",
            "Accuracy: 0.6496773125930829\n",
            "Confusion Matrix:\n",
            " [[  51   23   22    8    0]\n",
            " [  29   45   45   19    7]\n",
            " [  38   52  192  117   23]\n",
            " [  21   40  222  596  284]\n",
            " [  33   38  173  923 3042]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.30      0.49      0.37       104\n",
            "           2       0.23      0.31      0.26       145\n",
            "           3       0.29      0.45      0.36       422\n",
            "           4       0.36      0.51      0.42      1163\n",
            "           5       0.91      0.72      0.80      4209\n",
            "\n",
            "    accuracy                           0.65      6043\n",
            "   macro avg       0.42      0.50      0.44      6043\n",
            "weighted avg       0.73      0.65      0.68      6043\n",
            "\n",
            "Realizando validación cruzada...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   57.2s remaining:  1.4min\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'fit_time': array([37.69304633, 37.79300094, 35.10799766, 35.03504848, 21.41998935]), 'score_time': array([0.02499986, 0.0279994 , 0.03199935, 0.01999617, 0.02000642]), 'test_score': array([0.45870917, 0.44866661, 0.44730718, 0.44452941, 0.46830655])}\n",
            "Media de f1_macro en validación cruzada:  0.45350378604720143\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  1.3min finished\n"
          ]
        }
      ],
      "source": [
        "# Modelo REGRESIÓN LOGÍSITCA + TF-IDF\n",
        "clf_polarity = LogisticRegression(max_iter=30000, C=1.0, verbose=1)\n",
        "clf_polarity.fit(X_train_tfidf, y_train)\n",
        "\n",
        "y_pred = clf_polarity.predict(X_test_tfidf)\n",
        "\n",
        "print(y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "print('Realizando validación cruzada...')\n",
        "cv_results = cross_validate(clf_polarity, X_train_tfidf, y_train, cv=5, scoring='f1_macro', verbose=3, n_jobs=-1)\n",
        "\n",
        "print(cv_results)\n",
        "print('Media de f1_macro en validación cruzada: ', np.mean(cv_results['test_score']))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "clf_polarity = MLPClassifier(hidden_layer_sizes=(100,), max_iter = 1000, random_state=1)\n",
        "clf_polarity.fit(X_train_tfidf, y_train)\n",
        "\n",
        "y_pred = clf_polarity.predict(X_test_tfidf)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "print('Realizando validación cruzada...')\n",
        "cv_results = cross_validate(clf_polarity, X_train_tfidf, y_train, cv=5, scoring='f1_macro', verbose=3, n_jobs=-1)\n",
        "\n",
        "print(cv_results)\n",
        "print('Media de f1_macro en validación cruzada: ', np.mean(cv_results['test_score']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "x6WikOoktOiJ",
        "outputId": "d9182ff2-be8f-4023-99a2-3ad767d4f923"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-44b0ea18760c>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneural_network\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMLPClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mclf_polarity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMLPClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_layer_sizes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mclf_polarity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_tfidf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf_polarity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_tfidf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train_tfidf' is not defined"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}